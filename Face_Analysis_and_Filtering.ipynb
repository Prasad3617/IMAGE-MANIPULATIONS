{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prasad3617/IMAGE-MANIPULATIONS/blob/main/Face_Analysis_and_Filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b62886b",
      "metadata": {
        "id": "0b62886b"
      },
      "outputs": [],
      "source": [
        "import cv2                                               #import necessary libraries\n",
        "import dlib                                              #a library commonly used to work on machine learning algorithms\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "618ea648",
      "metadata": {
        "id": "618ea648"
      },
      "outputs": [],
      "source": [
        "PREDICTOR_PATH = \"shape_predictor_68_face_landmarks.dat\"     #creating a variable to store the file for predefined model\n",
        "predictor = dlib.shape_predictor(PREDICTOR_PATH)             #creating a method to utilise the variable declared above\n",
        "detector = dlib.get_frontal_face_detector()                  #deriving the method to detect frontal-face-features as we will see"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07283f54",
      "metadata": {
        "id": "07283f54"
      },
      "outputs": [],
      "source": [
        "class TooManyFaces(Exception):                  #handling the exceptions if any\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb9fb8ab",
      "metadata": {
        "id": "bb9fb8ab"
      },
      "outputs": [],
      "source": [
        "class NoFaces(Exception):                       #handling the exceptions if any\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cc739dc",
      "metadata": {
        "id": "0cc739dc"
      },
      "outputs": [],
      "source": [
        "def get_landmarks(im):                          #a function to get the numerical data for or identity for facial features\n",
        "    rects = detector(im, 1)\n",
        "\n",
        "    if len(rects) > 1:\n",
        "        raise TooManyFaces\n",
        "    if len(rects) == 0:\n",
        "        raise NoFaces\n",
        "\n",
        "    return numpy.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ee3b5dd",
      "metadata": {
        "id": "1ee3b5dd"
      },
      "outputs": [],
      "source": [
        "def annotate_landmarks(im, landmarks):          #function to label or annotate any facial feature which gets detected\n",
        "    im = im.copy()\n",
        "    for idx, point in enumerate(landmarks):\n",
        "        pos = (point[0, 0], point[0, 1])\n",
        "        cv2.putText(im, str(idx), pos,\n",
        "                    fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
        "                    fontScale=0.4,\n",
        "\n",
        "                    color=(0, 0, 255))\n",
        "        cv2.circle(im, pos, 3, color=(0, 255, 255))\n",
        "    return im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7882c6a",
      "metadata": {
        "id": "a7882c6a",
        "outputId": "a71832f1-db41-4552-d65e-b2cd71843750"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "113"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image = cv2.imread('15.jpeg')                    #loading and displaying the original image\n",
        "cv2.imshow(\"Original_Image\",image)\n",
        "cv2.waitKey(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21315aab",
      "metadata": {
        "id": "21315aab"
      },
      "outputs": [],
      "source": [
        "landmarks = get_landmarks(image)                                 #storing the landmarks\n",
        "image_with_landmarks = annotate_landmarks(image, landmarks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59daed35",
      "metadata": {
        "id": "59daed35"
      },
      "outputs": [],
      "source": [
        "cv2.imshow('Result', image_with_landmarks)                      #displaying the results for the facial analysis\n",
        "cv2.imwrite('image_with_landmarks.jpg',image_with_landmarks)\n",
        "cv2.waitKey(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46550b40",
      "metadata": {
        "id": "46550b40"
      },
      "outputs": [],
      "source": [
        "cv2.destroyAllWindows()                                          #destroying any windows"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}