{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's use our Pre-Trained Caffe Model to Colorize Some Photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script is based on https://github.com/richzhang/colorization/blob/master/colorize.py\n",
    "# To download the caffemodel and the prototxt, see: https://github.com/richzhang/colorization/tree/master/models\n",
    "# To download pts_in_hull.npy, see: https://github.com/richzhang/colorization/blob/master/resources/pts_in_hull.npy\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Get our images\n",
    "file_path = \"./blackandwhite/\"\n",
    "blackandwhite_imgs = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "kernel = 'pts_in_hull.npy'\n",
    "\n",
    "# Start the main program\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Select desired model\n",
    "    net = cv2.dnn.readNetFromCaffe(\"colorization_deploy_v2.prototxt\",\n",
    "                               \"colorization_release_v2.caffemodel\")\n",
    "\n",
    "    # load cluster centers\n",
    "    pts_in_hull = np.load(kernel) \n",
    "\n",
    "    # populate cluster centers as 1x1 convolution kernel\n",
    "    pts_in_hull = pts_in_hull.transpose().reshape(2, 313, 1, 1)\n",
    "    net.getLayer(net.getLayerId('class8_ab')).blobs = [pts_in_hull.astype(np.float32)]\n",
    "    net.getLayer(net.getLayerId('conv8_313_rh')).blobs = [np.full([1, 313], 2.606, np.float32)]\n",
    "\n",
    "    for image in blackandwhite_imgs:\n",
    "        img = cv2.imread(file_path+image)\n",
    "        \n",
    "        img_rgb = (img[:,:,[2, 1, 0]] * 1.0 / 255).astype(np.float32)\n",
    "        img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2LAB)\n",
    "        \n",
    "        # pull out L channel\n",
    "        img_l = img_lab[:,:,0]\n",
    "        # get original image size\n",
    "        (H_orig,W_orig) = img_rgb.shape[:2] \n",
    "\n",
    "        # resize image to network input size\n",
    "        img_rs = cv2.resize(img_rgb, (224, 224)) \n",
    "        \n",
    "        # resize image to network input size\n",
    "        img_lab_rs = cv2.cvtColor(img_rs, cv2.COLOR_RGB2Lab)\n",
    "        img_l_rs = img_lab_rs[:,:,0]\n",
    "        \n",
    "        # subtract 50 for mean-centering\n",
    "        img_l_rs -= 50 \n",
    "\n",
    "        net.setInput(cv2.dnn.blobFromImage(img_l_rs))\n",
    "        \n",
    "        # this is our result\n",
    "        ab_dec = net.forward('class8_ab')[0,:,:,:].transpose((1,2,0)) \n",
    "\n",
    "        (H_out,W_out) = ab_dec.shape[:2]\n",
    "        ab_dec_us = cv2.resize(ab_dec, (W_orig, H_orig))\n",
    "        img_lab_out = np.concatenate((img_l[:,:,np.newaxis],ab_dec_us),axis=2) \n",
    "        \n",
    "        # concatenate with original image L\n",
    "        img_bgr_out = np.clip(cv2.cvtColor(img_lab_out, cv2.COLOR_Lab2BGR), 0, 1)\n",
    "\n",
    "        # show original image\n",
    "        cv2.imshow('Original', img)\n",
    "        # Resize the corlized image to it's orginal dimensions \n",
    "        img_bgr_out = cv2.resize(img_bgr_out, (W_orig, H_orig), interpolation = cv2.INTER_AREA)\n",
    "        cv2.imshow('Colorized', img_bgr_out)\n",
    "        cv2.waitKey(0)\n",
    "        if cv2.waitKey(1) >= 0:\n",
    "            break\n",
    "                      \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's now colorize your webcam stream after converting to grayscale first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script is based on https://github.com/richzhang/colorization/blob/master/colorize.py\n",
    "# To download the caffemodel and the prototxt, see: https://github.com/richzhang/colorization/tree/master/models\n",
    "# To download pts_in_hull.npy, see: https://github.com/richzhang/colorization/blob/master/resources/pts_in_hull.npy\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "kernel = 'pts_in_hull.npy'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    imshowSize = (640, 480)\n",
    "\n",
    "    # Select desired model\n",
    "    net = cv2.dnn.readNetFromCaffe(\"colorization_deploy_v2.prototxt\", \"colorization_release_v2.caffemodel\")\n",
    "\n",
    "    pts_in_hull = np.load(kernel) # load cluster centers\n",
    "\n",
    "    # populate cluster centers as 1x1 convolution kernel\n",
    "    pts_in_hull = pts_in_hull.transpose().reshape(2, 313, 1, 1)\n",
    "    net.getLayer(net.getLayerId('class8_ab')).blobs = [pts_in_hull.astype(np.float32)]\n",
    "    net.getLayer(net.getLayerId('conv8_313_rh')).blobs = [np.full([1, 313], 2.606, np.float32)]\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while cv2.waitKey(1) < 0:\n",
    "        hasFrame, frame = cap.read()\n",
    "        if not hasFrame:\n",
    "            cv2.waitKey()\n",
    "\n",
    "        img_rgb = (frame[:,:,[2, 1, 0]] * 1.0 / 255).astype(np.float32)\n",
    "        img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2LAB)\n",
    "        img_l = img_lab[:,:,0] # pull out L channel\n",
    "        (H_orig,W_orig) = img_rgb.shape[:2] # original image size\n",
    "\n",
    "        # resize image to network input size\n",
    "        img_rs = cv2.resize(img_rgb, (224, 224)) # resize image to network input size\n",
    "        img_lab_rs = cv2.cvtColor(img_rs, cv2.COLOR_RGB2Lab)\n",
    "        img_l_rs = img_lab_rs[:,:,0]\n",
    "        img_l_rs -= 50 # subtract 50 for mean-centering\n",
    "\n",
    "        net.setInput(cv2.dnn.blobFromImage(img_l_rs))\n",
    "        ab_dec = net.forward('class8_ab')[0,:,:,:].transpose((1,2,0)) # this is our result\n",
    "\n",
    "        (H_out,W_out) = ab_dec.shape[:2]\n",
    "        ab_dec_us = cv2.resize(ab_dec, (W_orig, H_orig))\n",
    "        img_lab_out = np.concatenate((img_l[:,:,np.newaxis],ab_dec_us),axis=2) # concatenate with original image L\n",
    "        img_bgr_out = np.clip(cv2.cvtColor(img_lab_out, cv2.COLOR_Lab2BGR), 0, 1)\n",
    "\n",
    "        frame = cv2.resize(frame, imshowSize)\n",
    "        cv2.imshow('origin', frame)\n",
    "        cv2.imshow('gray', cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY))\n",
    "        cv2.imshow('colorized', cv2.resize(img_bgr_out, imshowSize))\n",
    "        if cv2.waitKey(1) >= 0:\n",
    "            break\n",
    "            \n",
    "cap.release()            \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
